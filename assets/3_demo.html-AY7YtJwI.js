import{_ as d,a as m,b as k,c as b,d as v}from"./robustness_test_plot-BrdrmNbU.js";import{_ as h,c as g,b as s,a as o,e as t,d as a,w as e,r as c,o as f}from"./app-CCtLKDl1.js";const y={};function _(w,n){const p=c("RouteLink"),r=c("Tabs"),u=c("CommentService");return f(),g("div",null,[n[38]||(n[38]=s("h1",{id:"case-three-implementing-your-own-model-with-benco-init",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#case-three-implementing-your-own-model-with-benco-init"},[s("span",null,[a("Case Three: Implementing Your Own Model with "),s("code",null,"benco init")])])],-1)),n[39]||(n[39]=s("p",null,'We believe that the fastest way to learn is "Learn by Doing" (learning by doing), so we use several cases to help users get started quickly.',-1)),n[40]||(n[40]=s("p",null,[a("Overall, IMDL-BenCo helps you quickly complete the development of image tampering detection scientific research projects through command line calls similar to "),s("code",null,"git"),a(" and "),s("code",null,"conda"),a(". If you have learned front-end technologies such as vue, understanding the design pattern of IMDLBenCo according to vue-cli will be very easy.")],-1)),s("p",null,[n[1]||(n[1]=a("Regardless, please refer to ")),t(p,{to:"/guide/quickstart/install.html"},{default:e(()=>n[0]||(n[0]=[a("Installation")])),_:1}),n[2]||(n[2]=a(" to complete the installation of IMDL-BenCo first."))]),n[41]||(n[41]=o('<div class="hint-container tip"><p class="hint-container-title">Motivation of This Chapter</p><p>To ensure that you can flexibly create your own models, this chapter will help you understand the design patterns and interface paradigms of IMDL-BenCo. We will introduce each part step by step according to the usage process.</p></div><h2 id="introducing-all-design-patterns" tabindex="-1"><a class="header-anchor" href="#introducing-all-design-patterns"><span>Introducing All Design Patterns</span></a></h2><h3 id="generating-default-scripts" tabindex="-1"><a class="header-anchor" href="#generating-default-scripts"><span>Generating Default Scripts</span></a></h3><p>Under a clean working path, executing the following command line instruction will generate all the scripts needed for <strong>creating your own model and testing</strong>. As a default instruction, omitting the base will also execute the same command.</p>',4)),t(r,{id:"26",data:[{id:"Full Command"},{id:"Abbreviated Command"}]},{title0:e(({value:i,isActive:l})=>n[3]||(n[3]=[a("Full Command")])),title1:e(({value:i,isActive:l})=>n[4]||(n[4]=[a("Abbreviated Command")])),tab0:e(({value:i,isActive:l})=>n[5]||(n[5]=[s("div",{class:"language-bash line-numbers-mode","data-highlighter":"prismjs","data-ext":"sh"},[s("pre",null,[s("code",null,[s("span",{class:"line"},"benco init base"),a(`
`),s("span",{class:"line"})])]),s("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[s("div",{class:"line-number"})])],-1)])),tab1:e(({value:i,isActive:l})=>n[6]||(n[6]=[s("div",{class:"language-bash line-numbers-mode","data-highlighter":"prismjs","data-ext":"sh"},[s("pre",null,[s("code",null,[s("span",{class:"line"},"benco init"),a(`
`),s("span",{class:"line"})])]),s("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[s("div",{class:"line-number"})])],-1)])),_:1}),n[42]||(n[42]=o(`<p>After normal execution, you will see the following files generated under the current path, and their uses are as commented:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token builtin class-name">.</span></span>
<span class="line">├── balanced_dataset.json       <span class="token comment"># Stores the dataset path organized according to Protocol-CAT</span></span>
<span class="line">├── mymodel.py                  <span class="token comment"># The core model implementation</span></span>
<span class="line">├── README-IMDLBenCo.md         <span class="token comment"># A simple readme</span></span>
<span class="line">├── test_datasets.json          <span class="token comment"># Stores the test dataset path</span></span>
<span class="line">├── test_mymodel.sh             <span class="token comment"># The shell script for running tests with parameters</span></span>
<span class="line">├── test.py                     <span class="token comment"># The actual Python code for the test script</span></span>
<span class="line">├── test_robust_mymodel.sh      <span class="token comment"># The shell script for running robustness tests with parameters</span></span>
<span class="line">├── test_robust.py              <span class="token comment"># The actual Python code for robustness tests</span></span>
<span class="line">├── train_mymodel.sh            <span class="token comment"># The shell script for running training with parameters</span></span>
<span class="line">└── train.py                    <span class="token comment"># The actual Python code for the training script</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">Special Attention</p><p>If the scripts have been generated and some modifications have been made, please be very careful when calling <code>benco init</code> for the second time. IMDLBenCo will cover the files one by one after asking, and if you operate incorrectly, it may cause you to lose your existing modifications. Be careful. It is recommended to use git version control to avoid losing existing code due to this operation.</p></div><h3 id="model-file-design-pattern" tabindex="-1"><a class="header-anchor" href="#model-file-design-pattern"><span>Model File Design Pattern</span></a></h3><p>IMDLBenCo needs to organize the model files in a certain format to ensure that the entry can align with the <code>DataLoader</code> and the exit can align with the subsequent <code>Evaluator</code> and <code>Visualize tools</code>.</p><p>After executing <code>benco init</code>, a model with the simplest <strong>single-layer convolution</strong> is generated in <code>mymodel.py</code> by default. You can quickly view its content through the <a href="https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/statics/base/mymodel.py" target="_blank" rel="noopener noreferrer">Github link to mymodel.py</a>.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">from</span> IMDLBenCo<span class="token punctuation">.</span>registry <span class="token keyword">import</span> MODELS</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</span>
<span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"></span>
<span class="line"><span class="token decorator annotation punctuation">@MODELS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">MyModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> MyModel_Customized_param<span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">,</span> pre_trained_weights<span class="token punctuation">:</span><span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token triple-quoted-string string">&quot;&quot;&quot;</span>
<span class="line">        The parameters of the \`__init__\` function will be automatically converted into the parameters expected by the argparser in the training and testing scripts by the framework according to their annotated types and variable names. </span>
<span class="line">        </span>
<span class="line">        In other words, you can directly pass in parameters with the same names and types from the \`run.sh\` script to initialize the model.</span>
<span class="line">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">        <span class="token comment"># Useless, just an example</span></span>
<span class="line">        self<span class="token punctuation">.</span>MyModel_Customized_param <span class="token operator">=</span> MyModel_Customized_param</span>
<span class="line">        self<span class="token punctuation">.</span>pre_trained_weights <span class="token operator">=</span> pre_trained_weights</span>
<span class="line"></span>
<span class="line">        <span class="token comment"># A single layer conv2d </span></span>
<span class="line">        self<span class="token punctuation">.</span>demo_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span></span>
<span class="line">            in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span></span>
<span class="line">            out_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">            kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span></span>
<span class="line">            stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">            padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># A simple loss</span></span>
<span class="line">        self<span class="token punctuation">.</span>loss_func_a <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> label<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># simple forwarding</span></span>
<span class="line">        pred_mask <span class="token operator">=</span> self<span class="token punctuation">.</span>demo_layer<span class="token punctuation">(</span>image<span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">        <span class="token comment"># simple loss</span></span>
<span class="line">        loss_a <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_func_a<span class="token punctuation">(</span>pred_mask<span class="token punctuation">,</span> mask<span class="token punctuation">)</span></span>
<span class="line">        loss_b <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>pred_mask <span class="token operator">-</span> mask<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        combined_loss <span class="token operator">=</span> loss_a <span class="token operator">+</span> loss_b</span>
<span class="line">        </span>
<span class="line">        </span>
<span class="line">        pred_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>pred_mask<span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">        inverse_mask <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> mask</span>
<span class="line">        </span>
<span class="line">        <span class="token comment"># ----------Output interface--------------------------------------</span></span>
<span class="line">        output_dict <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token comment"># loss for backward</span></span>
<span class="line">            <span class="token string">&quot;backward_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">            <span class="token comment"># predicted mask, will calculate for metrics automatically</span></span>
<span class="line">            <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> pred_mask<span class="token punctuation">,</span></span>
<span class="line">            <span class="token comment"># predicted binaray label, will calculate for metrics automatically</span></span>
<span class="line">            <span class="token string">&quot;pred_label&quot;</span><span class="token punctuation">:</span> pred_label<span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token comment"># ----values below is for visualization----</span></span>
<span class="line">            <span class="token comment"># automatically visualize with the key-value pairs</span></span>
<span class="line">            <span class="token string">&quot;visual_loss&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token comment"># keys here can be customized by yourself.</span></span>
<span class="line">                <span class="token string">&quot;predict_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&#39;loss_a&#39;</span> <span class="token punctuation">:</span> loss_a<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;I am loss_b :)&quot;</span><span class="token punctuation">:</span> loss_b<span class="token punctuation">,</span> </span>
<span class="line">            <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_image&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token comment"># keys here can be customized by yourself.</span></span>
<span class="line">                <span class="token comment"># Various intermediate masks, heatmaps, and feature maps can be appropriately converted into RGB or single-channel images for visualization here.</span></span>
<span class="line">                <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> pred_mask<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;reverse_mask&quot;</span> <span class="token punctuation">:</span> inverse_mask<span class="token punctuation">,</span> </span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">            <span class="token comment"># -------------------------------------------------------------</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">        </span>
<span class="line">        <span class="token keyword">return</span> output_dict</span>
<span class="line">    </span>
<span class="line">    </span>
<span class="line"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span>MODELS<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Introducing the design requirements of IMDLBenCo&#39;s model file from top to bottom:</strong></p><ul><li>Line 5: <code>@MODELS.register_module()</code><ul><li>Registers the model to IMDLBenCo&#39;s global registry based on the registration mechanism, making it easy for other scripts to quickly call the class through strings.</li><li>If you are not familiar with the registration mechanism, a one-sentence explanation is: <strong>It automatically maintains a dictionary mapping from strings to corresponding class mappings</strong>, making it easy to &quot;freely&quot; pass parameters.</li><li>In actual use, by passing the registered &quot;class name identical string&quot; to the <code>--model</code> function of the shell script that starts training, the framework can load the corresponding custom or built-in model. For details, please refer to <a href="https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/statics/model_zoo/runs/demo_train_mvss.sh#L10" target="_blank" rel="noopener noreferrer">this link</a>.</li></ul></li><li>Lines 29 and 37: <strong>Loss functions must be defined in the <code>__init__()</code> or <code>forward()</code> functions</strong></li><li>Line 31: Defining the forward function <code>def forward(self, image, mask, label, *args, **kwargs):</code><ul><li>It is necessary to include <code>*args, **kwargs</code> required for Python function unpacking to receive unused parameters. <ul><li>If you are not familiar with it, please refer to <a href="https://docs.python.org/3/tutorial/controlflow.html#keyword-arguments" target="_blank" rel="noopener noreferrer">Python Official Documentation-4.8.2. Keyword Arguments</a>, <a href="https://docs.python.org/zh-cn/3/tutorial/controlflow.html#keyword-arguments" target="_blank" rel="noopener noreferrer">Python Official Documentation Chinese Version-4.8.2 Keyword Arguments</a></li></ul></li><li>The parameter variable names must be exactly the same as the field names contained in the dictionary <code>data_dict</code> returned by <a href="https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/datasets/abstract_dataset.py" target="_blank" rel="noopener noreferrer"><code>abstract_dataset.py</code></a>. The default fields are shown in the table below: <ul><li><table><thead><tr><th style="text-align:center;">Key Name</th><th>Meaning</th><th style="text-align:center;">Type</th></tr></thead><tbody><tr><td style="text-align:center;">image</td><td>Input original image</td><td style="text-align:center;">Tensor(B,3,H,W)</td></tr><tr><td style="text-align:center;">mask</td><td>Mask of the prediction target</td><td style="text-align:center;">Tensor(B,1,H,W)</td></tr><tr><td style="text-align:center;">edge_mask</td><td>After <a href="https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html" target="_blank" rel="noopener noreferrer">erosion (erosion) and dilation (dilation)</a> based on the mask, only the boundary is white, which is used for various models that need boundary loss functions. To reduce computational overhead, the corresponding dataloader will only return this key-value pair for the model&#39;s <code>forward()</code> function when the <code>--edge_mask_width 7</code> parameter is passed in the training <code>shell</code>, refer to the <a href="https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/statics/model_zoo/runs/demo_train_iml_vit.sh#L22" target="_blank" rel="noopener noreferrer">shell</a> and <a href="https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/model_zoo/iml_vit/iml_vit.py#L125" target="_blank" rel="noopener noreferrer">model forward function</a> of <code>IML-ViT</code>.<br>If you do not need the boundary mask to calculate subsequent losses, you do not need to pass it in the shell, nor do you need to prepare a parameter named <code>edge_mask</code> in the model&#39;s <code>forward()</code> function, refer to the <a href="https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/statics/model_zoo/runs/demo_train_object_former.sh" target="_blank" rel="noopener noreferrer">shell</a> and <a href="https://github.com/scu-zjz/IMDLBenCo/blob/4c6a2937c3cae8d6ff26bf85e9bad0c5ec467468/IMDLBenCo/model_zoo/object_former/object_former.py#L285" target="_blank" rel="noopener noreferrer">model forward function</a> of <code>ObjectFormer</code>.</td><td style="text-align:center;">Tensor(B,1,H,W)</td></tr><tr><td style="text-align:center;">label</td><td>Image-level prediction of zero-one labels</td><td style="text-align:center;">Tensor(B,1)</td></tr><tr><td style="text-align:center;">shape</td><td>The shape of the image after padding or resizing</td><td style="text-align:center;">Tensor(B,2), two dimensions each with one value, representing H and W respectively</td></tr><tr><td style="text-align:center;">original_shape</td><td>The shape of the image when it was first read</td><td style="text-align:center;">Tensor(B,2), two dimensions each with one value, representing H and W respectively</td></tr><tr><td style="text-align:center;">name</td><td>The path and filename of the image</td><td style="text-align:center;">str</td></tr><tr><td style="text-align:center;">shape_mask</td><td>In the case of padding, only the pixels inside this mask that are 1 are calculated as the final metric, 1 defaults to a square area the same size as the original image</td><td style="text-align:center;">Tensor(B,1,H,W)</td></tr></tbody></table></li><li>For different tasks, you can take these fields as needed and input them into the model for use.</li><li>In addition, for the Jpeg-related image materials needed by CAT-Net, we have designed the post-processing function <code>post_func</code> to generate more content based on the existing fields. At this time, it is also necessary to ensure that the corresponding forward function&#39;s fields are aligned. <strong>Custom models with similar needs can also use this pattern to introduce other modal information in the dataloader.</strong> The following is a case of CAT-Net: <ul><li><a href="https://github.com/scu-zjz/IMDLBenCo/blob/c2d6dc03eab3f33461690d5026b43afdac22f70c/IMDLBenCo/model_zoo/cat_net/cat_net_post_function.py#L7-L10" target="_blank" rel="noopener noreferrer">Github link to <code>cat_net_post_function</code></a>, you can see that it includes two additional fields <code>DCT_coef</code> and <code>q_tables</code> for the model to input additional modalities</li><li><a href="https://github.com/scu-zjz/IMDLBenCo/blob/c2d6dc03eab3f33461690d5026b43afdac22f70c/IMDLBenCo/model_zoo/cat_net/cat_net.py#L30" target="_blank" rel="noopener noreferrer">Github link to <code>cat_net_model</code></a>, the <code>forward</code> function&#39;s parameter list needs to have corresponding fields to receive the above additional input information.</li></ul></li></ul></li></ul></li><li>Lines 36 to 38: All loss functions must be calculated in the <code>forward</code> function</li><li>Lines 45 to 70: The dictionary of output results. <span style="color:red;font-weight:bold;">Very important!</span>, the function of each field in the dictionary is introduced as follows: <ul><li><table><thead><tr><th style="text-align:center;">Key</th><th style="text-align:center;">Meaning</th><th style="text-align:center;">Type</th></tr></thead><tbody><tr><td style="text-align:center;">backward_loss</td><td style="text-align:center;">The loss function directly used for backpropagation</td><td style="text-align:center;">Tensor(1)</td></tr><tr><td style="text-align:center;">pred_mask</td><td style="text-align:center;">The predicted mask, which will be directly used for subsequent metric calculations</td><td style="text-align:center;">Tensor(B,1,H,W)</td></tr><tr><td style="text-align:center;">pred_label</td><td style="text-align:center;">The predicted zero-one label, which will be directly used for subsequent metric calculations</td><td style="text-align:center;">Tensor(B,1)</td></tr><tr><td style="text-align:center;">visual_loss</td><td style="text-align:center;">Pass in the scalars that need to be visualized. You can name any number, any name of keys and pass in the corresponding scalars, which will be automatically visualized according to the Key name later</td><td style="text-align:center;">Dict()</td></tr><tr><td style="text-align:center;">visual_image</td><td style="text-align:center;">Pass in the images, feature maps, various masks that need to be visualized. You can name any number, any name of keys and pass in the corresponding Tensors, which will be automatically visualized according to the Key name later</td><td style="text-align:center;">Dict()</td></tr></tbody></table></li><li>Be sure to organize according to this format to integrate normally into subsequent metric calculations, visualization, etc.</li></ul></li></ul><h2 id="step-by-step-comprehensive-tutorial" tabindex="-1"><a class="header-anchor" href="#step-by-step-comprehensive-tutorial"><span>Step-by-Step Comprehensive Tutorial</span></a></h2><p>We will use the <a href="https://arxiv.org/abs/2201.03545" target="_blank" rel="noopener noreferrer">ConvNeXt</a> as a model, CASIAv2 as the training set, and CASIAv1 as the test set to guide you through the process of designing, training, and testing your own new model with IMDL-BenCo from start to finish.</p><h3 id="downloading-datasets" tabindex="-1"><a class="header-anchor" href="#downloading-datasets"><span>Downloading Datasets</span></a></h3>`,12)),s("p",null,[n[8]||(n[8]=a("This repository provides an index directory, introduction, and errata for the current mainstream tampering detection datasets. Please refer to the ")),t(p,{to:"/imdl_data_model_hub/data/IMDLdatasets.html"},{default:e(()=>n[7]||(n[7]=[a("Tampering Detection Dataset Index")])),_:1}),n[9]||(n[9]=a(" section."))]),n[43]||(n[43]=o(`<div class="hint-container important"><p class="hint-container-title">Note</p><p>Many tampering detection datasets are manually annotated and collected, which leads to many errors, so necessary corrections are essential. Common errors include:</p><ol><li>Inconsistent image and mask resolutions;</li><li>Extra images without corresponding masks;</li><li>Obvious misalignment between images and masks;</li></ol><p>More information on corrections can be found in this <a href="https://github.com/SunnyHaze/IML-Dataset-Corrections" target="_blank" rel="noopener noreferrer">IML-Dataset-Corrections repository</a>.</p></div><ul><li>CASIAv2 download link: <ul><li>Please refer to the <code>Fixed groundtruth downloading</code> section in <a href="https://github.com/SunnyHaze/CASIA2.0-Corrected-Groundtruth" target="_blank" rel="noopener noreferrer">Sunnyhaze&#39;s repository</a> to download the complete dataset.</li></ul></li><li>CASIAv1 download link: <ul><li>Download the original dataset images from the cloud storage link in the Readme of <a href="https://github.com/namtpham/casia1groundtruth" target="_blank" rel="noopener noreferrer">namtpham&#39;s repository</a>.</li><li>Please clone this repository to download the corresponding masks for the images.<div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">git clone https://github.com/namtpham/casia1groundtruth</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul></li></ul><h3 id="organizing-datasets-into-a-format-readable-by-imdl-benco" tabindex="-1"><a class="header-anchor" href="#organizing-datasets-into-a-format-readable-by-imdl-benco"><span>Organizing Datasets into a Format Readable by IMDL-BenCo</span></a></h3>`,3)),s("p",null,[n[11]||(n[11]=a("Please refer to the ")),t(p,{to:"/guide/quickstart/0_dataprepare.html"},{default:e(()=>n[10]||(n[10]=[a("Dataset Preparation Section")])),_:1}),n[12]||(n[12]=a(" for specific format requirements."))]),n[44]||(n[44]=o(`<ul><li>The downloaded CASIAv2 dataset is already organized in the <code>ManiDataset</code> format and can be used directly after extraction.</li><li>The downloaded CASIAv1 dataset requires further processing. We provide two methods here, <code>JsonDataset</code> and <code>ManiDataset</code>.</li></ul><p>First, after extracting the original dataset <code>CASIA 1.0 dataset</code> provided by this repository, you can see the following files:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token builtin class-name">.</span></span>
<span class="line">├── Au.zip</span>
<span class="line">├── Authentic_list.txt</span>
<span class="line">├── Modified Tp.zip</span>
<span class="line">├── Modified_CopyMove_list.txt</span>
<span class="line">├── Modified_Splicing_list.txt</span>
<span class="line">├── Original Tp.zip</span>
<span class="line">├── Original_CopyMove_list.txt</span>
<span class="line">└── Original_Splicing_list.txt</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Due to some filename errors from the official CASIA, this repository has corrected these naming errors. In fact, we only need to extract the modified <code>Modified Tp.zip</code>, which results in:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">└── Tp</span>
<span class="line">    ├── CM</span>
<span class="line">    └── Sp</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Where <code>CM</code> contains the tampered images corresponding to <code>Copy-move</code>; and <code>SP</code> contains the tampered images corresponding to <code>Splicing</code>. There should be a total of 921 images in theory.</p><div class="hint-container warning"><p class="hint-container-title">Important!</p><p>According to the <a href="https://github.com/SunnyHaze/IML-Dataset-Corrections" target="_blank" rel="noopener noreferrer">errata repository</a>, there is an extra image without a corresponding mask, namely: <code>CASIA1.0/Modified Tp/Tp/Sp/Sp_D_NRN_A_cha0011_sec0011_0542.jpg</code>. We recommend removing this image from the dataset before proceeding with further processing.</p></div><p>Additionally, after extracting the <code>CASIA 1.0 groundtruth</code>, you get:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token builtin class-name">.</span></span>
<span class="line">└── CASIA <span class="token number">1.0</span> groundtruth</span>
<span class="line">    ├── CM</span>
<span class="line">    ├── CopyMove_groundtruth_list.txt</span>
<span class="line">    ├── FileNameCorrection.xlsx</span>
<span class="line">    ├── Sp</span>
<span class="line">    └── Splicing_groundtruth_list.txt</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Similarly, <code>CM</code> contains the masks corresponding to <code>Copy-move</code>; and <code>SP</code> contains the masks corresponding to <code>Splicing</code>. There should be 920 images in theory. <strong>To ensure one-to-one correspondence between images and masks, please remove the extra image from the tampered images as mentioned above</strong>.</p><p>Next, we demonstrate how to organize CASIAv1 into a dataset readable by IMDL-BenCo in two ways.</p><h4 id="organizing-dataset-with-jsondataset" tabindex="-1"><a class="header-anchor" href="#organizing-dataset-with-jsondataset"><span>Organizing Dataset with JsonDataset</span></a></h4><p>You can generate a <code>JSON</code> file readable by IMDL-BenCo by executing the following Python script in the set path:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">import</span> os</span>
<span class="line"><span class="token keyword">import</span> json</span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">collect_image_paths</span><span class="token punctuation">(</span>root_dir<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;Collect the relative and absolute paths of all image files in the directory&quot;&quot;&quot;</span></span>
<span class="line">    image_exts <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&#39;.jpg&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.jpeg&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.png&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.bmp&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.tif&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.tiff&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.webp&#39;</span><span class="token punctuation">}</span></span>
<span class="line">    image_paths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    pwd <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">for</span> dirpath<span class="token punctuation">,</span> _<span class="token punctuation">,</span> filenames <span class="token keyword">in</span> os<span class="token punctuation">.</span>walk<span class="token punctuation">(</span>root_dir<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">for</span> filename <span class="token keyword">in</span> filenames<span class="token punctuation">:</span></span>
<span class="line">            file_ext <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splitext<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">            <span class="token keyword">if</span> file_ext <span class="token keyword">in</span> image_exts<span class="token punctuation">:</span></span>
<span class="line">                abs_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>normpath<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dirpath<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">                image_paths<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>pwd<span class="token punctuation">,</span> abs_path<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> image_paths</span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">generate_pairs</span><span class="token punctuation">(</span>image_root<span class="token punctuation">,</span> mask_root<span class="token punctuation">,</span> output_json<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token comment"># Collect image paths</span></span>
<span class="line">    image_dict <span class="token operator">=</span> collect_image_paths<span class="token punctuation">(</span>image_root<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Number of images found:&quot;</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>image_dict<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    mask_dict <span class="token operator">=</span> collect_image_paths<span class="token punctuation">(</span>mask_root<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Number of masks found:&quot;</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>mask_dict<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>image_dict<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>mask_dict<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;The number of images {} and the number of masks {} do not match!&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_dict<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>mask_dict<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token comment"># Generate pairing list</span></span>
<span class="line">    pairs <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">        <span class="token builtin">list</span><span class="token punctuation">(</span>pairs<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">for</span> pairs <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>image_dict<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>mask_dict<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">]</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span>pairs<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># Save as JSON file</span></span>
<span class="line">    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>output_json<span class="token punctuation">,</span> <span class="token string">&#39;w&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></span>
<span class="line">        json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>pairs<span class="token punctuation">,</span> f<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Successfully generated </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> pairs of paths, results saved to </span><span class="token interpolation"><span class="token punctuation">{</span>output_json<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> pairs</span>
<span class="line"></span>
<span class="line"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token comment"># Configure paths (modify according to actual situation)</span></span>
<span class="line">    IMAGE_ROOT <span class="token operator">=</span> <span class="token string">&quot;Tp&quot;</span></span>
<span class="line">    MASK_ROOT <span class="token operator">=</span> <span class="token string">&quot;CASIA 1.0 groundtruth&quot;</span></span>
<span class="line">    OUTPUT_JSON <span class="token operator">=</span> <span class="token string">&quot;CASIAv1.json&quot;</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># Execute generation</span></span>
<span class="line">    result_pairs <span class="token operator">=</span> generate_pairs<span class="token punctuation">(</span>IMAGE_ROOT<span class="token punctuation">,</span> MASK_ROOT<span class="token punctuation">,</span> OUTPUT_JSON<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># Print the last 5 pairs as an example to verify alignment</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\nLast five example pairs:&quot;</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">for</span> pair <span class="token keyword">in</span> result_pairs<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Image: </span><span class="token interpolation"><span class="token punctuation">{</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Mask:  </span><span class="token interpolation"><span class="token punctuation">{</span>pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">\\n&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>For example, I generated a <code>json</code> file like this:</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json"><pre><code><span class="line"><span class="token punctuation">[</span></span>
<span class="line">  <span class="token punctuation">[</span></span>
<span class="line">    <span class="token string">&quot;/mnt/data0/xiaochen/workspace/IMDLBenCo_pure/guide/Tp/CM/Sp_S_CND_A_pla0016_pla0016_0196.jpg&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;/mnt/data0/xiaochen/workspace/IMDLBenCo_pure/guide/CASIA 1.0 groundtruth/CM/Sp_S_CND_A_pla0016_pla0016_0196_gt.png&quot;</span></span>
<span class="line">  <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">   ......</span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Subsequently, you can write the absolute path of this json file as the test set parameter in the shell, for example:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">/mnt/data0/xiaochen/workspace/IMDLBenCo_pure/guide/CASIAv1.json</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Note that, if you build your own dataset with real images later, you need to write the path of the <code>mask</code> for real images as the string <code>Negative</code> when building the JSON script. This way, <code>Benco</code> will treat this image as a real image with a pure black mask. For example, if you want to use the above image as a real image, the json should be organized like this:</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json"><pre><code><span class="line"><span class="token punctuation">[</span></span>
<span class="line">  <span class="token punctuation">[</span></span>
<span class="line">    <span class="token string">&quot;/mnt/data0/xiaochen/workspace/IMDLBenCo_pure/guide/Tp/CM/Sp_S_CND_A_pla0016_pla0016_0196.jpg&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;Negative&quot;</span></span>
<span class="line">  <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">   ......</span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="organizing-dataset-with-manidataset" tabindex="-1"><a class="header-anchor" href="#organizing-dataset-with-manidataset"><span>Organizing Dataset with ManiDataset</span></a></h4><p>Very simple, find a clean path to store the dataset and create a folder named <code>CASIAv1</code>, then create two subfolders with the following names:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">└── CASIAv1</span>
<span class="line">    ├── Tp</span>
<span class="line">    └── Gt</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then copy the 920 tampered images to the <code>Tp</code> path and copy the 920 masks to the <code>Gt</code> path. Subsequently, you can write the path of this folder as the test set parameter in the shell, for example:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">/mnt/data0/xiaochen/workspace/IMDLBenCo_pure/guide/CASIAv1</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="adjusting-the-design-of-your-own-model-under-benco-init" tabindex="-1"><a class="header-anchor" href="#adjusting-the-design-of-your-own-model-under-benco-init"><span>Adjusting the Design of Your Own Model under benco init</span></a></h3><p>First, we need to execute <code>benco init</code> to generate all the required files and scripts. A brief introduction to the generated files has been given in the first half of this chapter.</p><p>To customize your own model, you need to modify <code>mymodel.py</code>. We will first provide the modified code and then introduce the important parts.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">from</span> IMDLBenCo<span class="token punctuation">.</span>registry <span class="token keyword">import</span> MODELS</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</span>
<span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F</span>
<span class="line"><span class="token keyword">import</span> timm</span>
<span class="line"></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">ConvNeXtDecoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;Adapted ConvNeXt feature decoder&quot;&quot;&quot;</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoder_channels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decoder_channels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># Use transposed convolution for upsampling step by step</span></span>
<span class="line">        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></span>
<span class="line">            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>encoder_channels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decoder_channels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 16x16 -&gt; 64x64</span></span>
<span class="line">            nn<span class="token punctuation">.</span>GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            </span>
<span class="line">            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>decoder_channels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decoder_channels<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 64x64 -&gt; 256x256</span></span>
<span class="line">            nn<span class="token punctuation">.</span>GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            </span>
<span class="line">            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>decoder_channels<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decoder_channels<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            nn<span class="token punctuation">.</span>GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            </span>
<span class="line">            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>decoder_channels<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decoder_channels<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            nn<span class="token punctuation">.</span>GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            </span>
<span class="line">            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>decoder_channels<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token decorator annotation punctuation">@MODELS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">MyConvNeXt</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Initialize ConvNeXt-Tiny backbone network</span></span>
<span class="line">        self<span class="token punctuation">.</span>backbone <span class="token operator">=</span> timm<span class="token punctuation">.</span>create_model<span class="token punctuation">(</span></span>
<span class="line">            <span class="token string">&quot;convnext_tiny&quot;</span><span class="token punctuation">,</span></span>
<span class="line">            pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></span>
<span class="line">            features_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></span>
<span class="line">            out_indices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># Take the last feature map (1/32 downsampling)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Segmentation decoder</span></span>
<span class="line">        self<span class="token punctuation">.</span>seg_decoder <span class="token operator">=</span> ConvNeXtDecoder<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Classification head</span></span>
<span class="line">        self<span class="token punctuation">.</span>cls_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></span>
<span class="line">            nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">768</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># ConvNeXt-Tiny&#39;s last channel count is 768</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Loss functions</span></span>
<span class="line">        self<span class="token punctuation">.</span>seg_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>cls_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> label<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># Feature extraction</span></span>
<span class="line">        features <span class="token operator">=</span> self<span class="token punctuation">.</span>backbone<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># Get the last feature map [B, 768, H/32, W/32]</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Segmentation prediction</span></span>
<span class="line">        seg_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>seg_decoder<span class="token punctuation">(</span>features<span class="token punctuation">)</span></span>
<span class="line">        seg_pred <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>seg_pred<span class="token punctuation">,</span> size<span class="token operator">=</span>mask<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&#39;bilinear&#39;</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Classification prediction</span></span>
<span class="line">        cls_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_head<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Calculate losses</span></span>
<span class="line">        seg_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>seg_loss<span class="token punctuation">(</span>seg_pred<span class="token punctuation">,</span> mask<span class="token punctuation">)</span></span>
<span class="line">        cls_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_loss<span class="token punctuation">(</span>cls_pred<span class="token punctuation">,</span> label<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        combined_loss <span class="token operator">=</span> seg_loss <span class="token operator">+</span> cls_loss</span>
<span class="line"></span>
<span class="line">        <span class="token comment"># Build output dictionary</span></span>
<span class="line">        output_dict <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token string">&quot;backward_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>seg_pred<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;pred_label&quot;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>cls_pred<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_loss&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;total_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;seg_loss&quot;</span><span class="token punctuation">:</span> seg_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;cls_loss&quot;</span><span class="token punctuation">:</span> cls_loss</span>
<span class="line">            <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_image&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> seg_pred<span class="token punctuation">,</span></span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">        <span class="token keyword">return</span> output_dict</span>
<span class="line"></span>
<span class="line"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token comment"># Test code</span></span>
<span class="line">    model <span class="token operator">=</span> MyConvNeXt<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span></span>
<span class="line">    mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span></span>
<span class="line">    label <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Note that the label dimension is adjusted to [batch_size]</span></span>
<span class="line">    output <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> label<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([2, 1, 512, 512])</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token string">&quot;pred_label&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([2])</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>We first renamed the model class to <code>class MyConvNeXt(nn.Module)</code>. Only the entry of the complete model needs to add the <code>@MODELS.register_module()</code> decorator to complete global registration. The previous submodule <code>class ConvNeXtDecoder(nn.Module):</code> does not need to be called directly by IMDL-BenCo, so there is no need to register it or maintain a special interface.</p><p>It can be noted that the loss functions are defined inside the <code>__init__()</code> function and calculated in the <code>forward()</code> function.</p><p>The final output dictionary returns the following according to the interface format:</p><ol><li><code>backward_loss</code>, the loss function;</li><li><code>pred_mask</code>, the pixel-level prediction result of the segmentation head, which is a 0~1 probability map and will be automatically used to calculate all pixel-level metrics, such as <code>pixel-level F1</code>;</li><li><code>pred_label</code>, the image-level prediction result of the classification head, which is a 0~1 probability value and will be automatically used for all image-level metrics, such as <code>image-level AUC</code>;</li><li><code>visual_loss</code>, a dictionary of scalar loss functions for visualization, plotting a line chart for each scalar according to the numerical changes per Epoch;</li><li><code>visual_image</code>, a dictionary of prediction tensors for observing the predicted mask, displaying all tensors in the dictionary through the tensorboard API.</li></ol><div class="hint-container important"><p class="hint-container-title">Important</p><p>This dictionary is an important interface for IMDL-BenCo to automatically complete calculations and visualizations. Please be sure to master it.</p></div><h3 id="modify-other-scripts" tabindex="-1"><a class="header-anchor" href="#modify-other-scripts"><span>Modify Other Scripts</span></a></h3><p>First, since some information in <code>mymodel.py</code> has been modified, you need to modify the corresponding file interfaces. Mainly includes the following places:</p><ul><li>The beginning of <code>train.py</code>, <code>test.py</code>, and <code>test_robust.py</code> regarding the model&#39;s <code>import</code> is modified to the corresponding model name <ul><li>Originally <code>from mymodel import MyModel</code>, here it is modified to the new model name <code>from mymodel import MyConvNeXt</code></li><li>Of course, if you change the file name of <code>mymodel.py</code>, it is also possible, as long as the corresponding import is consistent.</li><li>If not imported, IMDL-BenCo will not be able to find the corresponding model during subsequent training.</li></ul></li></ul><div class="hint-container important"><p class="hint-container-title">Important TODOs Awaiting Your Modifications</p><p>There are many <code>TODO</code> comments in the files <code>train.py</code>, <code>test.py</code>, and <code>test_robust.py</code>, which are intended to encourage you to make active modifications.</p><p>For example, if you want to introduce metrics such as <code>Pixel-AUC</code>, you will also need to manually modify the corresponding <code>TODO</code> sections to achieve this.</p></div><hr>`,39)),s("ul",null,[s("li",null,[n[26]||(n[26]=a("The script ")),n[27]||(n[27]=s("code",null,"train_mymodel.sh",-1)),n[28]||(n[28]=a(" is the shell script to start training and definitely needs to be modified. ")),s("ul",null,[n[22]||(n[22]=s("li",null,[a("Change the "),s("code",null,"--model"),a(" field to "),s("code",null,"MyConvNeXt"),a(", the model will automatically match the corresponding model based on this string from the registered classes.")],-1)),s("li",null,[n[14]||(n[14]=a("Since this model's ")),n[15]||(n[15]=s("code",null,"__init__()",-1)),n[16]||(n[16]=a(" function has no parameters, the two redundant parameters ")),n[17]||(n[17]=s("code",null,"--MyModel_Customized_param",-1)),n[18]||(n[18]=a(" and ")),n[19]||(n[19]=s("code",null,"--pre_trained_weights",-1)),n[20]||(n[20]=a(" shown in this example can be directly deleted. The documentation for this technique is in the ")),t(p,{to:"/guide/quickstart/1_model_zoo.html#Passing-nn-module-hyperparameters-through-shell-syntax-sugar"},{default:e(()=>n[13]||(n[13]=[a("Passing nn.Module Hyperparameters through Shell")])),_:1}),n[21]||(n[21]=a(" section."))]),n[23]||(n[23]=s("li",null,[a("Modify the "),s("code",null,"--data_path"),a(" field to the prepared training set path.")],-1)),n[24]||(n[24]=s("li",null,[a("Modify the "),s("code",null,"--test_data_path"),a(" field to the previously prepared test set path.")],-1)),n[25]||(n[25]=s("li",null,[a("Modify other training hyperparameters to match your device requirements, computational efficiency, etc. Here is an example of a modified "),s("code",null,"train_mymodel.sh"),a(".")],-1))])])]),n[45]||(n[45]=o(`<div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token assign-left variable">base_dir</span><span class="token operator">=</span><span class="token string">&quot;./output_dir&quot;</span></span>
<span class="line"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> <span class="token variable">\${base_dir}</span></span>
<span class="line"></span>
<span class="line"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\\</span></span>
<span class="line">torchrun  <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--standalone</span>    <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nnodes</span><span class="token operator">=</span><span class="token number">1</span>     <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">./train.py <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--model</span> MyConvNeXt <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--world_size</span> <span class="token number">1</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--batch_size</span> <span class="token number">32</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_batch_size</span> <span class="token number">32</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--num_workers</span> <span class="token number">8</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--data_path</span> /mnt/data0/public_datasets/IML/CASIA2.0 <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--epochs</span> <span class="token number">200</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--lr</span> 1e-4 <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--image_size</span> <span class="token number">512</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--if_resizing</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--min_lr</span> 5e-7 <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--weight_decay</span> <span class="token number">0.05</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--edge_mask_width</span> <span class="token number">7</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_data_path</span> <span class="token string">&quot;/mnt/data0/public_datasets/IML/CASIA1.0&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--warmup_epochs</span> <span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--output_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--log_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--accum_iter</span> <span class="token number">8</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--seed</span> <span class="token number">42</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_period</span> <span class="token number">4</span> <span class="token punctuation">\\</span></span>
<span class="line"><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span> <span class="token variable">\${base_dir}</span>/error.log <span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span><span class="token variable">\${base_dir}</span>/logs.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Here I have two graphics cards, so I set <code>CUDA_VISIBLE_DEVICES=0,1</code> and <code>--nproc_per_node=2</code>, you can modify it to the number supported by your device and the corresponding graphics card number.</p><h3 id="conduct-training" tabindex="-1"><a class="header-anchor" href="#conduct-training"><span>Conduct Training</span></a></h3><p>Then, execute the following command in the working directory to start training:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token function">sh</span> train_mymodel.sh</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>If there is no output, don&#39;t panic, in order to save logs, <strong>all outputs and errors are redirected to files.</strong></p><p>If run correctly, a folder named <code>output_dir_xxx</code> or <code>eval_dir_xxx</code> will be generated in the current path, which outputs three logs, one is the normal standard output <code>logs.log</code>, one is warnings and errors <code>error.log</code>. There is also an independent log file specifically for statistical vectors <code>log.txt</code></p><p>If the model runs normally, you should be able to see the model continuously iterating and outputting new logs at the end of <code>logs.log</code>:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token punctuation">[</span>01:51:01.408908<span class="token punctuation">]</span> Epoch: <span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span> Total time: <span class="token number">0</span>:00:47 <span class="token punctuation">(</span><span class="token number">0.5883</span> s / it<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span>01:51:08.313768<span class="token punctuation">]</span> Averaged stats: lr: <span class="token number">0.000051</span>  total_loss: <span class="token number">0.0379</span> <span class="token punctuation">(</span><span class="token number">0.0425</span><span class="token punctuation">)</span>  seg_loss: <span class="token number">0.0379</span> <span class="token punctuation">(</span><span class="token number">0.0425</span><span class="token punctuation">)</span>  cls_loss: <span class="token number">0.0000</span> <span class="token punctuation">(</span><span class="token number">0.0000</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span>01:51:08.319097<span class="token punctuation">]</span> log_dir: ./output_dir/</span>
<span class="line"><span class="token punctuation">[</span>01:51:12.473905<span class="token punctuation">]</span> Epoch: <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>  <span class="token punctuation">[</span> <span class="token number">0</span>/80<span class="token punctuation">]</span>  eta: <span class="token number">0</span>:05:32  lr: <span class="token number">0.000051</span>  total_loss: <span class="token number">0.0415</span> <span class="token punctuation">(</span><span class="token number">0.0415</span><span class="token punctuation">)</span>  seg_loss: <span class="token number">0.0415</span> <span class="token punctuation">(</span><span class="token number">0.0415</span><span class="token punctuation">)</span>  cls_loss: <span class="token number">0.0000</span> <span class="token punctuation">(</span><span class="token number">0.0000</span><span class="token punctuation">)</span>  time: <span class="token number">4.1538</span>  data: <span class="token number">2.5060</span>  max mem: <span class="token number">12775</span></span>
<span class="line"><span class="token punctuation">[</span>01:51:23.468235<span class="token punctuation">]</span> Epoch: <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>  <span class="token punctuation">[</span><span class="token number">20</span>/80<span class="token punctuation">]</span>  eta: <span class="token number">0</span>:00:43  lr: <span class="token number">0.000051</span>  total_loss: <span class="token number">0.0383</span> <span class="token punctuation">(</span><span class="token number">0.0426</span><span class="token punctuation">)</span>  seg_loss: <span class="token number">0.0383</span> <span class="token punctuation">(</span><span class="token number">0.0426</span><span class="token punctuation">)</span>  cls_loss: <span class="token number">0.0000</span> <span class="token punctuation">(</span><span class="token number">0.0000</span><span class="token punctuation">)</span>  time: <span class="token number">0.5496</span>  data: <span class="token number">0.0083</span>  max mem: <span class="token number">12775</span></span>
<span class="line"><span class="token punctuation">[</span>01:51:34.303514<span class="token punctuation">]</span> Epoch: <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>  <span class="token punctuation">[</span><span class="token number">40</span>/80<span class="token punctuation">]</span>  eta: <span class="token number">0</span>:00:25  lr: <span class="token number">0.000051</span>  total_loss: <span class="token number">0.0354</span> <span class="token punctuation">(</span><span class="token number">0.0406</span><span class="token punctuation">)</span>  seg_loss: <span class="token number">0.0354</span> <span class="token punctuation">(</span><span class="token number">0.0406</span><span class="token punctuation">)</span>  cls_loss: <span class="token number">0.0000</span> <span class="token punctuation">(</span><span class="token number">0.0000</span><span class="token punctuation">)</span>  time: <span class="token number">0.5417</span>  data: <span class="token number">0.0002</span>  max mem: <span class="token number">12775</span></span>
<span class="line"><span class="token punctuation">[</span>01:51:45.128389<span class="token punctuation">]</span> Epoch: <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>  <span class="token punctuation">[</span><span class="token number">60</span>/80<span class="token punctuation">]</span>  eta: <span class="token number">0</span>:00:12  lr: <span class="token number">0.000050</span>  total_loss: <span class="token number">0.0304</span> <span class="token punctuation">(</span><span class="token number">0.0401</span><span class="token punctuation">)</span>  seg_loss: <span class="token number">0.0304</span> <span class="token punctuation">(</span><span class="token number">0.0401</span><span class="token punctuation">)</span>  cls_loss: <span class="token number">0.0000</span> <span class="token punctuation">(</span><span class="token number">0.0000</span><span class="token punctuation">)</span>  time: <span class="token number">0.5412</span>  data: <span class="token number">0.0002</span>  max mem: <span class="token number">12775</span></span>
<span class="line"><span class="token punctuation">[</span>01:51:55.408163<span class="token punctuation">]</span> Epoch: <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>  <span class="token punctuation">[</span><span class="token number">79</span>/80<span class="token punctuation">]</span>  eta: <span class="token number">0</span>:00:00  lr: <span class="token number">0.000050</span>  total_loss: <span class="token number">0.0366</span> <span class="token punctuation">(</span><span class="token number">0.0394</span><span class="token punctuation">)</span>  seg_loss: <span class="token number">0.0366</span> <span class="token punctuation">(</span><span class="token number">0.0394</span><span class="token punctuation">)</span>  cls_loss: <span class="token number">0.0000</span> <span class="token punctuation">(</span><span class="token number">0.0000</span><span class="token punctuation">)</span>  time: <span class="token number">0.5409</span>  data: <span class="token number">0.0001</span>  max mem: <span class="token number">12775</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>According to the above settings, this example occupies two graphics cards, with each card occupying <code>4104M</code> of memory.</p><p>Here is a recommended tool to check graphics card usage, <code>gpustat</code>. After installing <code>pip install gpustat</code> and executing <code>gpustat</code> in the command line, you can easily view the graphics card usage and corresponding users. For example, here you can see the first two cards I used while writing this tutorial:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">psdz           Mon Mar <span class="token number">31</span> <span class="token number">22</span>:51:55 <span class="token number">2025</span>  <span class="token number">570.124</span>.06</span>
<span class="line"><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> NVIDIA A40 <span class="token operator">|</span> <span class="token number">44</span>°C, <span class="token number">100</span> % <span class="token operator">|</span> <span class="token number">18310</span> / <span class="token number">46068</span> MB <span class="token operator">|</span> psdz<span class="token punctuation">(</span>17442M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>4M<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> NVIDIA A40 <span class="token operator">|</span> <span class="token number">45</span>°C,  <span class="token number">35</span> % <span class="token operator">|</span> <span class="token number">18310</span> / <span class="token number">46068</span> MB <span class="token operator">|</span> psdz<span class="token punctuation">(</span>17442M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>4M<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> NVIDIA A40 <span class="token operator">|</span> <span class="token number">65</span>°C, <span class="token number">100</span> % <span class="token operator">|</span> <span class="token number">40153</span> / <span class="token number">46068</span> MB <span class="token operator">|</span> xuekang<span class="token punctuation">(</span>38666M<span class="token punctuation">)</span> xuekang<span class="token punctuation">(</span>482M<span class="token punctuation">)</span> xuekang<span class="token punctuation">(</span>482M<span class="token punctuation">)</span> xuekang<span class="token punctuation">(</span>482M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>4M<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> NVIDIA A40 <span class="token operator">|</span> <span class="token number">76</span>°C, <span class="token number">100</span> % <span class="token operator">|</span> <span class="token number">38602</span> / <span class="token number">46068</span> MB <span class="token operator">|</span> xuekang<span class="token punctuation">(</span>38452M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>108M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>14M<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> NVIDIA A40 <span class="token operator">|</span> <span class="token number">59</span>°C, <span class="token number">100</span> % <span class="token operator">|</span> <span class="token number">38466</span> / <span class="token number">46068</span> MB <span class="token operator">|</span> xuekang<span class="token punctuation">(</span>38444M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>4M<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> NVIDIA A40 <span class="token operator">|</span> <span class="token number">63</span>°C, <span class="token number">100</span> % <span class="token operator">|</span> <span class="token number">38478</span> / <span class="token number">46068</span> MB <span class="token operator">|</span> xuekang<span class="token punctuation">(</span>38456M<span class="token punctuation">)</span> gdm<span class="token punctuation">(</span>4M<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>At this point, you can execute the following command to bring up <code>tensorboard</code> to monitor the training process:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">tensorboard <span class="token parameter variable">--logdir</span> ./  </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Open the corresponding URL it provides. If you are using a server, vscode or pycharm will help you forward this port to the corresponding port on your local computer. Hold down the ctrl key and click on the corresponding link. I am accessing here:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">http://localhost:6006/</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>In Tensorboard, we can see many useful metrics that can monitor the training process and the convergence of the model. They all correspond to the information in the dictionary returned by the <code>forward()</code> function of the model in <code>my_model.py</code>.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Build the output dictionary</span></span>
<span class="line">        output_dict <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token string">&quot;backward_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>seg_pred<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;pred_label&quot;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>cls_pred<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_loss&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;total_loss&quot;</span><span class="token punctuation">:</span> combined_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;seg_loss&quot;</span><span class="token punctuation">:</span> seg_loss<span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;cls_loss&quot;</span><span class="token punctuation">:</span> cls_loss</span>
<span class="line">            <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">            <span class="token string">&quot;visual_image&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;pred_mask&quot;</span><span class="token punctuation">:</span> seg_pred<span class="token punctuation">,</span></span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">        <span class="token keyword">return</span> output_dict</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The visualization of the loss function corresponds to the dictionary corresponding to the <code>visual_loss</code> field:</p><p><img src="`+d+'" alt=""></p><p>The calculation of the evaluation metrics comes from the results of <code>pred_mask</code> and <code>pred_label</code> and is obtained by calculating with <code>mask</code>:</p><p><img src="'+m+'" alt="alt text"></p><p>The visualization of the predicted results, obtained from the <code>visual_image</code> field, and the default input images such as <code>image</code>, <code>mask</code> are also automatically visualized and output, which can be used to directly observe where the model&#39;s current predictions are not good, facilitating further model improvement.</p><p><img src="'+k+`" alt=""></p><div class="hint-container note"><p class="hint-container-title">Note</p><p>The tutorial should have image samples here. If you do not see the images, please check your network connection or enable VPN.</p></div><p>All the weights obtained after training (Checkpoint) are saved in the path corresponding to <code>base_dir</code> at the beginning of the training <code>train_mymodel.sh</code> script. The log files of Tensorboard are also saved here for subsequent use and log review.</p><p>In addition to Tensorboard logs, we also provide a plain text log <code>log.txt</code> for archiving, which contains simple content, including all scalar information after each Epoch. An example is as follows:</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">......</span>
<span class="line">{&quot;train_lr&quot;: 5.068414063259753e-05, &quot;train_total_loss&quot;: 0.040027402791482446, &quot;train_seg_loss&quot;: 0.04001608065957309, &quot;train_cls_loss&quot;: 1.1322131909352606e-05, &quot;test_pixel-level F1&quot;: 0.6269838496863315, &quot;epoch&quot;: 100}</span>
<span class="line">{&quot;train_lr&quot;: 4.9894792537480576e-05, &quot;train_total_loss&quot;: 0.03938291078949974, &quot;train_seg_loss&quot;: 0.039372251576574625, &quot;train_cls_loss&quot;: 1.0659212925112626e-05, &quot;epoch&quot;: 101}</span>
<span class="line">{&quot;train_lr&quot;: 4.910553386394297e-05, &quot;train_total_loss&quot;: 0.039195733024078264, &quot;train_seg_loss&quot;: 0.039184275720948555, &quot;train_cls_loss&quot;: 1.1457303129702722e-05, &quot;epoch&quot;: 102}</span>
<span class="line">{&quot;train_lr&quot;: 4.8316563303634596e-05, &quot;train_total_loss&quot;: 0.0385435631179897, &quot;train_seg_loss&quot;: 0.03853294577689024, &quot;train_cls_loss&quot;: 1.061734109946144e-05, &quot;epoch&quot;: 103}</span>
<span class="line">{&quot;train_lr&quot;: 4.752807947567499e-05, &quot;train_total_loss&quot;: 0.035692626619510615, &quot;train_seg_loss&quot;: 0.03568181328162471, &quot;train_cls_loss&quot;: 1.0813337885906548e-05, &quot;test_pixel-level F1&quot;: 0.6672104743469334, &quot;epoch&quot;: 104}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The model is tested every 4 Epochs, so only the corresponding epoch will save <code>test_pixel-level F1</code>.</p><p>Thus, we have explained all the output content during the training process.</p><h3 id="conducting-tests" tabindex="-1"><a class="header-anchor" href="#conducting-tests"><span>Conducting Tests</span></a></h3><p>We saw in the previous metric tests that the model still had an upward trend at the 104th Epoch, but to save time, we stopped training here and proceeded to subsequent tests.</p><p>The gap between tamper detection datasets is quite large, and generalization performance is the most important indicator to measure model performance, so we hope to measure all indicators at once. Unlike previous tutorials, we need to use the <code>test_datasets.json</code> file that can cover multiple test datasets at once to assist in testing. The format is as follows, and we also provide a sample of this file in the files after <code>benco init</code>.</p><div class="language-JSON line-numbers-mode" data-highlighter="prismjs" data-ext="JSON"><pre><code><span class="line">{</span>
<span class="line">    &quot;Columbia&quot;: &quot;/mnt/data0/public_datasets/IML/Columbia.json&quot;,</span>
<span class="line">    &quot;NIST16_1024&quot;: &quot;/mnt/data0/public_datasets/IML/NIST16_1024&quot;,</span>
<span class="line">    &quot;NIST16_cleaned&quot;: &quot;/mnt/data0/public_datasets/IML/NIST16_1024_cleaning&quot;,</span>
<span class="line">    &quot;coverage&quot;: &quot;/mnt/data0/public_datasets/IML/coverage.json&quot;,</span>
<span class="line">    &quot;CASIAv1&quot;: &quot;/mnt/data0/public_datasets/IML/CASIA1.0&quot;,</span>
<span class="line">    &quot;IMD20_1024&quot;: &quot;/mnt/data0/public_datasets/IML/IMD_20_1024&quot;</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,34)),s("p",null,[n[31]||(n[31]=a("You need to preprocess each dataset in advance, and the dataset index is in the ")),t(p,{to:"/imdl_data_model_hub/data/IMDLdatasets.html"},{default:e(()=>n[29]||(n[29]=[a("Tamper Detection Dataset Index")])),_:1}),n[32]||(n[32]=a(" section, and the format requirements are in the ")),t(p,{to:"/guide/quickstart/0_dataprepare.html"},{default:e(()=>n[30]||(n[30]=[a("Dataset Preparation Section")])),_:1}),n[33]||(n[33]=a(". The above paths must be organized in the format of ")),n[34]||(n[34]=s("code",null,"ManiDataset",-1)),n[35]||(n[35]=a(" or ")),n[36]||(n[36]=s("code",null,"JsonDataset",-1)),n[37]||(n[37]=a("."))]),n[46]||(n[46]=o(`<p>Then we modify the <code>test_mymodel.sh</code> file to pass in the correct parameters, mainly including the following fields:</p><ul><li>Change <code>--mymodel</code> to <code>MyConvNeXt</code></li><li>Remove unnecessary <code>--MyModel_Customized_param</code> and <code>--pre_trained_weights</code> especially <code>pretrained_path</code> is usually initialized before model training. It is irrelevant during the testing phase.</li><li>Set <code>--checkpoint_path</code> to the folder where all <code>checkpoint-xx.pth</code> are output during training. It will automatically read all files ending with <code>.pth</code> under this folder and determine which epoch the checkpoint comes from based on the number in the filename to correctly plot the test metrics line chart.</li><li>Set <code>--test_data_json</code> to the path of the JSON containing multiple test set information mentioned earlier.</li><li>Other parameters can be set according to the memory and other conditions as appropriate,</li></ul><div class="hint-container important"><p class="hint-container-title">Note</p><p>If you chose <code>--if_padding</code> during training, this means that the dataloader will organize all images in the 0-padding manner of <a href="https://github.com/SunnyHaze/IML-ViT" target="_blank" rel="noopener noreferrer">IML-ViT</a>, not the <code>--if_resizing</code> of most models. Then make sure that this parameter is consistent between training and testing, otherwise, there will definitely be performance loss due to the inconsistency between the training set and the test set.</p><p>You can double-check whether padding or resizing is correctly selected through the pictures visualized by Tensorboard!</p></div><p>A modified <code>test_mymodel.sh</code> is as follows:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token assign-left variable">base_dir</span><span class="token operator">=</span><span class="token string">&quot;./eval_dir&quot;</span></span>
<span class="line"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> <span class="token variable">\${base_dir}</span></span>
<span class="line"></span>
<span class="line"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\\</span></span>
<span class="line">torchrun  <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--standalone</span>    <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nnodes</span><span class="token operator">=</span><span class="token number">1</span>     <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">./test.py <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--model</span> MyConvNeXt <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--world_size</span> <span class="token number">1</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_data_json</span> <span class="token string">&quot;./test_datasets.json&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--checkpoint_path</span> <span class="token string">&quot;./output_dir/&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_batch_size</span> <span class="token number">32</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--image_size</span> <span class="token number">512</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--if_resizing</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--output_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--log_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line"><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span> <span class="token variable">\${base_dir}</span>/error.log <span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span><span class="token variable">\${base_dir}</span>/logs.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then, remember to change <code>from mymodel import MyModel</code> at the beginning of <code>test.py</code> to <code>from mymodel import MyConvNeXt</code>.</p><p>At this point, running the following command can start batch testing metrics on various test sets:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token function">sh</span> test_mymodel.sh</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>At this time, you can also view the test progress and results through Tensorboard. You can filter <code>eval_dir</code> in the <code>filter</code> box on the left to only view the output results of this test.</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">tensorboard <span class="token parameter variable">--logdir</span> ./</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>The line charts of metrics obtained from multiple datasets after testing are as follows. Choose the Checkpoint with the best comprehensive performance and record the corresponding data in the paper.</p><p><img src="`+b+`" alt=""></p><h3 id="robustness-testing" tabindex="-1"><a class="header-anchor" href="#robustness-testing"><span>Robustness Testing</span></a></h3><p>Robustness testing introduces two dimensions of &quot;attack type&quot; and &quot;attack strength&quot; for grid search (<code>gird search</code>), so it is generally only the best-performing checkpoint during the test phase that undergoes robustness testing.</p><p>Accordingly, in the <code>test_robust_mymodel.sh</code> file, unlike <code>test_mymodel.sh</code>, the <code>--checkpoint_path</code> field here points to a specific checkpoint, not a folder.</p><p>The other fields are the same, remove unnecessary parameters, fill in the required parameters, and remember to change <code>from mymodel import MyModel</code> at the beginning of <code>test_robust.py</code> to <code>from mymodel import MyConvNeXt</code>.</p><p>The <code>test_robust_mymodel.sh</code> I finally used is as follows:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token assign-left variable">base_dir</span><span class="token operator">=</span><span class="token string">&quot;./eval_robust_dir&quot;</span></span>
<span class="line"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> <span class="token variable">\${base_dir}</span></span>
<span class="line"></span>
<span class="line"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\\</span></span>
<span class="line">torchrun  <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--standalone</span>    <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nnodes</span><span class="token operator">=</span><span class="token number">1</span>     <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">./test_robust.py <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--model</span> MyConvNeXt <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--world_size</span> <span class="token number">1</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_data_path</span> <span class="token string">&quot;/mnt/data0/public_datasets/IML/CASIA1.0&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--checkpoint_path</span> <span class="token string">&quot;/mnt/data0/xiaochen/workspace/IMDLBenCo_pure/guide/benco/output_dir/checkpoint-92.pth&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--test_batch_size</span> <span class="token number">32</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--image_size</span> <span class="token number">512</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--if_resizing</span> <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--output_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line">    <span class="token parameter variable">--log_dir</span> <span class="token variable">\${base_dir}</span>/ <span class="token punctuation">\\</span></span>
<span class="line"><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span> <span class="token variable">\${base_dir}</span>/error.log <span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span><span class="token variable">\${base_dir}</span>/logs.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The specific adjustment of attack strategies and intensities in robustness testing requires modification of <code>test_robust.py</code>. Please locate this modifiable code by searching for <code>TODO</code>:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;=================================================</span>
<span class="line">    Modify here to Set the robustness test parameters TODO</span>
<span class="line">    ===================================================&quot;&quot;&quot;</span></span>
<span class="line">    robustness_list <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">            GaussianBlurWrapper<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            GaussianNoiseWrapper<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> </span>
<span class="line">            JpegCompressionWrapper<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The lists behind these <code>wrapper</code> represent the specific strengths of the attacks, and they internally encapsulate the Transform provided by <a href="https://github.com/albumentations-team/albumentations" target="_blank" rel="noopener noreferrer">Albumentation</a> to implement the attack. The implementation of the <code>wrapper</code> itself, please refer to this <a href="https://github.com/scu-zjz/IMDLBenCo/blob/main/IMDLBenCo/transforms/robustness_wrapper.py" target="_blank" rel="noopener noreferrer">link</a>.</p><p>In particular, you can refer to the implementation of the <code>wrapper</code> in the current path to encapsulate a new custom <code>wrapper</code>, and then import your own wrapper here like <code>from mymodel import MyConvNeXt</code>. This way, you can achieve a custom flexible robustness test without modifying the source code.</p><hr><p>For test results, similarly, you can view them through Tensorboard:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">tensorboard <span class="token parameter variable">--logdir</span> ./</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>At this time, there may be many different records. Please make good use of the filter function in the upper left corner of Tensorboard to filter the attack types and corresponding results you need to record.</p><p><img src="`+v+'" alt=""></p><hr><h3 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h3><p>In this way, we have completed the process of designing a model from scratch, training the model, completing testing and robustness testing. If you have any questions or incomplete places, please feel free to raise issues in our repository or contact the author team by email. The suggestions from the first-hand users will be of great help to us and to future scholars!</p>',30)),t(u)])}const M=h(y,[["render",_]]),C=JSON.parse('{"path":"/guide/quickstart/3_demo.html","title":"Case Three: Implementing Your Own Model with benco init","lang":"en-US","frontmatter":{"description":"Case Three: Implementing Your Own Model with benco init We believe that the fastest way to learn is \\"Learn by Doing\\" (learning by doing), so we use several cases to help users g...","head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/zh/guide/quickstart/3_demo.html"}],["meta",{"property":"og:url","content":"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/guide/quickstart/3_demo.html"}],["meta",{"property":"og:site_name","content":"IMDLBenCo Documentation"}],["meta",{"property":"og:title","content":"Case Three: Implementing Your Own Model with benco init"}],["meta",{"property":"og:description","content":"Case Three: Implementing Your Own Model with benco init We believe that the fastest way to learn is \\"Learn by Doing\\" (learning by doing), so we use several cases to help users g..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/images/training/training_loss.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-04-03T10:12:18.000Z"}],["meta",{"property":"article:modified_time","content":"2025-04-03T10:12:18.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Case Three: Implementing Your Own Model with benco init\\",\\"image\\":[\\"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/images/training/training_loss.png\\",\\"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/images/training/pixelF1.png\\",\\"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/images/training/train_test_samples.png\\",\\"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/images/training/testing_results.png\\",\\"https://scu-zjz.github.io/IMDLBenCo-doc/IMDLBenCo-doc/images/training/robustness_test_plot.png\\"],\\"dateModified\\":\\"2025-04-03T10:12:18.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"Introducing All Design Patterns","slug":"introducing-all-design-patterns","link":"#introducing-all-design-patterns","children":[{"level":3,"title":"Generating Default Scripts","slug":"generating-default-scripts","link":"#generating-default-scripts","children":[]},{"level":3,"title":"Model File Design Pattern","slug":"model-file-design-pattern","link":"#model-file-design-pattern","children":[]}]},{"level":2,"title":"Step-by-Step Comprehensive Tutorial","slug":"step-by-step-comprehensive-tutorial","link":"#step-by-step-comprehensive-tutorial","children":[{"level":3,"title":"Downloading Datasets","slug":"downloading-datasets","link":"#downloading-datasets","children":[]},{"level":3,"title":"Organizing Datasets into a Format Readable by IMDL-BenCo","slug":"organizing-datasets-into-a-format-readable-by-imdl-benco","link":"#organizing-datasets-into-a-format-readable-by-imdl-benco","children":[]},{"level":3,"title":"Adjusting the Design of Your Own Model under benco init","slug":"adjusting-the-design-of-your-own-model-under-benco-init","link":"#adjusting-the-design-of-your-own-model-under-benco-init","children":[]},{"level":3,"title":"Modify Other Scripts","slug":"modify-other-scripts","link":"#modify-other-scripts","children":[]},{"level":3,"title":"Conduct Training","slug":"conduct-training","link":"#conduct-training","children":[]},{"level":3,"title":"Conducting Tests","slug":"conducting-tests","link":"#conducting-tests","children":[]},{"level":3,"title":"Robustness Testing","slug":"robustness-testing","link":"#robustness-testing","children":[]},{"level":3,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]}]}],"git":{"updatedTime":1743675138000,"contributors":[{"name":"Ma Xiaochen (马晓晨)","username":"","email":"mxch1122@126.com","commits":4}],"changelog":[{"hash":"3adb8aa2f1fd3408eb9837aa011bf7048ae6230b","time":1743675138000,"email":"mxch1122@126.com","author":"Ma Xiaochen (马晓晨)","message":"[update] add comment plugin to all pages."},{"hash":"c131b603f94f974b69bdb6ca4dfc284ba7e4c78f","time":1743461235000,"email":"mxch1122@126.com","author":"Ma Xiaochen (马晓晨)","message":"[update] finish case3 in tutorial"},{"hash":"54af2b8d8daf2f629ee69c364e4f45f21559e778","time":1743441654000,"email":"mxch1122@126.com","author":"Ma Xiaochen (马晓晨)","message":"[update] add more content to 3_demo"},{"hash":"2e30180fb8a110e32a3aa5fe308d2e0a030c47ec","time":1743364035000,"email":"mxch1122@126.com","author":"Ma Xiaochen (马晓晨)","message":"Revise sturcture, add more infor about data &amp; models."}]},"filePathRelative":"guide/quickstart/3_demo.md","autoDesc":true}');export{M as comp,C as data};
